# Crawl4AI å®Œæ•´åŠŸèƒ½æµ‹è¯•é¡¹ç›®

ä¸€ä¸ªåŸºäº [Crawl4AI](https://github.com/unclecode/crawl4ai) çš„å®Œæ•´åŠŸèƒ½æµ‹è¯•å’Œæ¼”ç¤ºé¡¹ç›®ã€‚

## ğŸš€ ç‰¹æ€§

- âœ… **åŸºç¡€çˆ¬å–**: ç®€å•å¿«é€Ÿçš„ç½‘é¡µå†…å®¹æå–
- âœ… **æ™ºèƒ½è¿‡æ»¤**: PruningContentFilter å’Œ BM25ContentFilter
- âœ… **å¤šæ ¼å¼å¯¼å‡º**: Markdownã€PDFã€æˆªå›¾
- âœ… **æ‰¹é‡å¤„ç†**: æ”¯æŒå¤šURLå¹¶å‘çˆ¬å–
- âœ… **é«˜çº§é…ç½®**: è‡ªå®šä¹‰æµè§ˆå™¨ã€ç¼“å­˜ã€ç­‰å¾…ç­–ç•¥
- âœ… **å®ç”¨å·¥å…·**: å‘½ä»¤è¡Œå·¥å…·ï¼Œå¼€ç®±å³ç”¨

## ğŸ“¦ å®‰è£…

```bash
# å®‰è£…ä¾èµ–
pip install -U crawl4ai nest_asyncio

# å®‰è£…æµè§ˆå™¨é©±åŠ¨
python -m playwright install
```

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: è¿è¡Œæµ‹è¯•è„šæœ¬

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_basic.py

# é«˜çº§åŠŸèƒ½æµ‹è¯•  
python test_advanced.py

# æ‰©å±•åŠŸèƒ½æµ‹è¯•
python test_extended_fix.py
```

### æ–¹æ³•2: ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·

```bash
# ç®€å•çˆ¬å–
python crawl_utility.py simple https://example.com

# æ™ºèƒ½æ¸…æ´—
python crawl_utility.py clean https://example.com -k "å…³é”®è¯"

# å¯¼å‡ºPDF
python crawl_utility.py pdf https://example.com

# æˆªå›¾
python crawl_utility.py screenshot https://example.com

# æå–ä¿¡æ¯
python crawl_utility.py info https://example.com

# æ‰¹é‡çˆ¬å–
python crawl_utility.py batch example_urls.txt
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
b_crawlforai/
â”œâ”€â”€ ğŸ“„ README.md              # é¡¹ç›®ä»‹ç»
â”œâ”€â”€ ğŸ“š PROJECT_GUIDE.md       # è¯¦ç»†ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ ğŸ§ª test_basic.py          # åŸºç¡€åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ ğŸ”§ test_advanced.py       # é«˜çº§åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ ğŸš€ test_extended_fix.py   # æ‰©å±•åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ ğŸ› ï¸ crawl_utility.py       # å‘½ä»¤è¡Œå·¥å…·
â”œâ”€â”€ ğŸ“ example_urls.txt       # ç¤ºä¾‹URLåˆ—è¡¨
â””â”€â”€ ğŸ“‚ outputs/               # è¾“å‡ºç›®å½•
    â”œâ”€â”€ ğŸ“„ markdown/          # Markdownæ–‡ä»¶
    â”œâ”€â”€ ğŸ“„ pdf/              # PDFæ–‡ä»¶
    â”œâ”€â”€ ğŸ–¼ï¸ screenshots/       # æˆªå›¾æ–‡ä»¶
    â”œâ”€â”€ ğŸ“Š json/             # JSONæ•°æ®
    â””â”€â”€ ğŸ“‹ reports/          # æµ‹è¯•æŠ¥å‘Š
```

## ğŸ¨ åŠŸèƒ½å±•ç¤º

### å†…å®¹è¿‡æ»¤æ•ˆæœå¯¹æ¯”

| è¿‡æ»¤æ–¹å¼ | å†…å®¹é•¿åº¦ | å‹ç¼©ç‡ | ç”¨é€” |
|---------|---------|--------|------|
| åŸå§‹å†…å®¹ | 10,881å­—ç¬¦ | 0% | å®Œæ•´å†…å®¹ |
| PruningContentFilter | 7,122å­—ç¬¦ | 34.5% | å»é™¤å™ªéŸ³ |
| BM25å…³é”®è¯è¿‡æ»¤ | 1,860å­—ç¬¦ | 82.9% | ç²¾å‡†æå– |

### è¾“å‡ºæ ¼å¼æ”¯æŒ

- ğŸ“ **Markdown**: æ¸…æ™°çš„æ–‡æœ¬æ ¼å¼
- ğŸ“„ **PDF**: é«˜è´¨é‡æ–‡æ¡£å¯¼å‡º  
- ğŸ–¼ï¸ **PNG**: å…¨é¡µé¢æˆªå›¾
- ğŸ“Š **JSON**: ç»“æ„åŒ–æ•°æ®

## ğŸ”§ é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰æµè§ˆå™¨é…ç½®

```python
browser_config = BrowserConfig(
    browser_type="chromium",
    headless=True,
    viewport_width=1920,
    viewport_height=1080
)
```

### æ™ºèƒ½å†…å®¹è¿‡æ»¤

```python
# ç§»é™¤å¯¼èˆªã€é¡µè„šç­‰å™ªéŸ³
content_filter = PruningContentFilter()

# åŸºäºå…³é”®è¯è¿‡æ»¤
content_filter = BM25ContentFilter(user_query="AI technology")
```

### æ‰¹é‡å¤„ç†

```python
urls = ["url1", "url2", "url3"]
async with AsyncWebCrawler() as crawler:
    tasks = [crawler.arun(url=url) for url in urls]
    results = await asyncio.gather(*tasks)
```

## ğŸ“š æ–‡æ¡£

- ğŸ“– [è¯¦ç»†ä½¿ç”¨æŒ‡å—](PROJECT_GUIDE.md)
- ğŸŒ [å®˜æ–¹æ–‡æ¡£](https://crawl4ai.com/mkdocs/)
- ğŸ“º [è§†é¢‘æ•™ç¨‹](https://www.bilibili.com/video/BV1Vx4y1g7bp/)
- ğŸ’» [Google Colab](https://colab.research.google.com/drive/1wz8u30rvbq6Scodye9AGCw8Qg_Z8QGsk)

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

MIT License

---

â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªæ˜Ÿæ ‡ï¼ 