#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¿®å¤ç‰ˆBM25å†…å®¹è¿‡æ»¤æµ‹è¯•
"""

import asyncio
import os
import nest_asyncio

nest_asyncio.apply()

OUTPUT_PATH = 'outputs/markdown/'

def output_md(base_filename, md_str):
    """ä¿å­˜markdownå†…å®¹åˆ°æ–‡ä»¶"""
    os.makedirs(OUTPUT_PATH, exist_ok=True)
    
    length = len(md_str)
    name, ext = os.path.splitext(base_filename)
    filename = f"{name}({length}){ext}"
    
    full_path = os.path.join(OUTPUT_PATH, filename)
    
    with open(full_path, 'w', encoding='utf-8') as f:
        f.write(md_str)
    
    print(f"å·²ä¿å­˜åˆ°: {full_path}")
    return full_path

async def test_bm25_content_filter_fixed():
    """æµ‹è¯•ä¿®å¤ç‰ˆBM25å†…å®¹è¿‡æ»¤"""
    try:
        print("ğŸ”¤ æµ‹è¯•ä¿®å¤ç‰ˆBM25å†…å®¹è¿‡æ»¤...")
        
        from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode, BrowserConfig
        from crawl4ai.content_filter_strategy import BM25ContentFilter
        from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator
        
        # æµè§ˆå™¨é…ç½®
        browser_config = BrowserConfig(
            headless=True,
            viewport_width=1280,
            viewport_height=720,
            user_agent='Chrome/114.0.0.0',
            text_mode=True,
        )
        
        # å…ˆæ£€æŸ¥BM25ContentFilterçš„æ­£ç¡®å‚æ•°
        print("æ£€æŸ¥BM25ContentFilterå‚æ•°...")
        try:
            # å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
            content_filter = BM25ContentFilter(
                user_query="ANTHROPIC API"
            )
            print("âœ… BM25ContentFilteråˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"å°è¯•å…¶ä»–å‚æ•°: {e}")
            try:
                content_filter = BM25ContentFilter(
                    query="ANTHROPIC API"
                )
                print("âœ… BM25ContentFilteråˆ›å»ºæˆåŠŸ (ä½¿ç”¨queryå‚æ•°)")
            except Exception as e2:
                print(f"å†æ¬¡å°è¯•: {e2}")
                content_filter = BM25ContentFilter()
                print("âœ… BM25ContentFilteråˆ›å»ºæˆåŠŸ (ä½¿ç”¨é»˜è®¤å‚æ•°)")
        
        # çˆ¬è™«è¿è¡Œé…ç½®
        run_config = CrawlerRunConfig(
            cache_mode=CacheMode.DISABLED,
            markdown_generator=DefaultMarkdownGenerator(
                content_filter=content_filter,
                options={
                    "ignore_links": True,
                    "ignore_images": True,
                }
            ),
        )
        
        # åˆ›å»ºçˆ¬è™«å¹¶æ‰§è¡Œ
        async with AsyncWebCrawler(config=browser_config) as crawler:
            result = await crawler.arun(
                url="https://www.anthropic.com/news/agent-capabilities-api",
                config=run_config,
            )
            
            # ä¿å­˜åŸå§‹å†…å®¹
            print(f"åŸå§‹Markdowné•¿åº¦: {len(result.markdown.raw_markdown)}")
            output_md('2_2_3_BM25ContentFilter_raw.md', result.markdown.raw_markdown)
            
            # ä¿å­˜è¿‡æ»¤åå†…å®¹
            print(f"âœ… BM25è¿‡æ»¤åMarkdowné•¿åº¦: {len(result.markdown.fit_markdown)}")
            output_md('2_2_3_BM25ContentFilter_fit.md', result.markdown.fit_markdown)
            
        return True
        
    except Exception as e:
        print(f"âŒ BM25è¿‡æ»¤æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    await test_bm25_content_filter_fixed()

if __name__ == "__main__":
    asyncio.run(main()) 