#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Crawl4AI åŸºç¡€æµ‹è¯•è„šæœ¬
æŒ‰ç…§æ•™ç¨‹é€æ­¥æµ‹è¯•å„é¡¹åŠŸèƒ½
"""

import asyncio
import os
import nest_asyncio
from playwright.async_api import async_playwright

# å…è®¸åœ¨Jupyterä¸­ä½¿ç”¨å¼‚æ­¥æ“ä½œ
nest_asyncio.apply()

# è®¾ç½®è¾“å‡ºè·¯å¾„
OUTPUT_PATH = 'outputs/markdown/'

def output_md(base_filename, md_str):
    """ä¿å­˜markdownå†…å®¹åˆ°æ–‡ä»¶"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(OUTPUT_PATH, exist_ok=True)
    
    # ç”Ÿæˆå¸¦é•¿åº¦çš„æ–‡ä»¶å
    length = len(md_str)
    name, ext = os.path.splitext(base_filename)
    filename = f"{name}({length}){ext}"
    
    # å®Œæ•´è·¯å¾„
    full_path = os.path.join(OUTPUT_PATH, filename)
    
    with open(full_path, 'w', encoding='utf-8') as f:
        f.write(md_str)
    
    print(f"å·²ä¿å­˜åˆ°: {full_path}")
    return full_path

def check_version():
    """æ£€æŸ¥Crawl4AIç‰ˆæœ¬"""
    try:
        import crawl4ai
        version = crawl4ai.__version__.__version__
        print(f"âœ… Crawl4AIç‰ˆæœ¬: {version}")
        return True
    except Exception as e:
        print(f"âŒ Crawl4AIç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")
        return False

async def test_browser():
    """æµ‹è¯•æµè§ˆå™¨åŠŸèƒ½"""
    try:
        print("ğŸ”§ æµ‹è¯•æµè§ˆå™¨åŠŸèƒ½...")
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            await page.goto('https://example.com')
            title = await page.title()
            print(f"âœ… æµè§ˆå™¨æµ‹è¯•æˆåŠŸ! æ ‡é¢˜: {title}")
            await browser.close()
        return True
    except Exception as e:
        print(f"âŒ æµè§ˆå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_basic_crawl(output_filename):
    """åŸºç¡€çˆ¬è™«æµ‹è¯•"""
    try:
        print("ğŸ•·ï¸ å¼€å§‹åŸºç¡€çˆ¬è™«æµ‹è¯•...")
        
        from crawl4ai import AsyncWebCrawler
        
        # åˆ›å»ºçˆ¬è™«å¯¹è±¡ï¼Œè‡ªåŠ¨ç®¡ç†èµ„æº
        async with AsyncWebCrawler() as crawler:
            # è®¿é—®æŒ‡å®šç½‘å€å¹¶ç­‰å¾…å“åº”
            result = await crawler.arun("https://www.anthropic.com/news/agent-capabilities-api")
            
            # æ‰“å°æŠ“å–ç»“æœ
            print(f"âœ… æŠ“å–æˆåŠŸ! Markdowné•¿åº¦: {len(result.markdown)}")
            print("ğŸ“ å‰300å­—ç¬¦é¢„è§ˆ:")
            print(result.markdown[:300])
            print("..." if len(result.markdown) > 300 else "")
            
            # ä¿å­˜åˆ°.mdæ–‡ä»¶
            saved_path = output_md(output_filename, result.markdown)
            print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {saved_path}")
            
        return True
        
    except Exception as e:
        print(f"âŒ åŸºç¡€çˆ¬è™«æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹Crawl4AIæµ‹è¯•...")
    print("=" * 50)
    
    # 1. æ£€æŸ¥ç‰ˆæœ¬
    if not check_version():
        return
        
    # 2. æµ‹è¯•æµè§ˆå™¨
    if not await test_browser():
        return
        
    # 3. æµ‹è¯•åŸºç¡€çˆ¬è™«
    if not await test_basic_crawl('1_1_Basic.md'):
        return
        
    print("=" * 50)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")

if __name__ == "__main__":
    asyncio.run(main()) 